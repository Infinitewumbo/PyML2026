{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXQSrVGLbfCq"
      },
      "source": [
        "# Lab 4: Basic regression - Predict fuel efficiency\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9HUhbCGbfCr"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IZf-mK3kbfCs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # we use this library to load the dataset\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ceGRpBIbfCs"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3MF2KLxHbfCs"
      },
      "outputs": [],
      "source": [
        "# Load the 'mpg' dataset using seaborn library into a Pandas DataFrame\n",
        "df = sns.load_dataset('mpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfxdDYPNbfCs"
      },
      "source": [
        "MPG dataset can be viewed online at  \n",
        "https://github.com/mwaskom/seaborn-data/blob/master/mpg.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzRgjAwp9hYw"
      },
      "source": [
        "## Data Exploration - Pandas Review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESV9y917bfCt"
      },
      "source": [
        "### Show the first 5 rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iKKH1ZrrbfCt"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5UukwBAdgXb"
      },
      "source": [
        "### Show the size of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1hfYc4Zdd1iL"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4UwwzRrd9WY"
      },
      "source": [
        "### Find the columns name and their types (numerical or categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TSNv_Siqd3xl"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heVHvJgZhc53"
      },
      "source": [
        "### Find the number of missing values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "imTo-ss8hy48"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJyFFJi_j186"
      },
      "source": [
        "### Handle the missing values in the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "695skg69ikSP"
      },
      "source": [
        "Since the number of missing values is low, we can simply drop the rows containing them. However, as a practice and review, let's substitute the missing values in the numerical columns (if any) with the mean of the respective column and the missing values in the categorical columns (if any) with the median of the respective column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aE2UQsu0j843"
      },
      "outputs": [],
      "source": [
        "#your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXeUz8BArqXK"
      },
      "source": [
        "### Compute the average and the median weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VuzHC1werwiv"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb5hLSIYsZE1"
      },
      "source": [
        "### Find the number of cars that weight more than 2000 kgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eDfsiR1Ysf0q"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3nE8VBksl20"
      },
      "source": [
        "### Find how many cars there are for each number of cylinders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-865t6xpsy4c"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4ofBIrVtQRS"
      },
      "source": [
        "### Find what are the car models with number of cylinders (3 or 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CtKqSLQxtOOb"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35WxtvxtU-X_"
      },
      "source": [
        "### Show the `value_counts()` of `origin` column or show the unique values of this column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UoQRTFJBU-tF"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGRxYTsrXLJf"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzIQgkXiVYBX"
      },
      "source": [
        "### Use one hot encoding to change the categorical values of `origin` column to numerical values.\n",
        "\n",
        "- use `pd.get_dummies()` method to do the encoding\n",
        "- Join the original DataFrame with the new dummy DataFrame with `pd.concat()` and use `axis=1` to concate in horizontal direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "x1AjXTQbQ5Uz"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtLp74JWXPp6"
      },
      "source": [
        "### Remove the `name` and `origin` column form the dataframe to have all numerical dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "V1A0DsEVXgXm"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuJ1dAYdY8JM"
      },
      "source": [
        "### Does the input needs reshaping?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "F68KMJTztVzS"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Form features `X` and labels `y` based on the processed datafram"
      ],
      "metadata": {
        "id": "33gOtZsc31sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n",
        "X = None\n",
        "y = None"
      ],
      "metadata": {
        "id": "N0Y3oPqE4TTP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDwS5PqJaqb7"
      },
      "source": [
        "### Split the data into training and test sets and form `train_features`, `train_labels`, `test_features`, `test_labels`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SZPxsIJcapzq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#your code here\n",
        "train_features, test_features, train_labels, test_labels = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePcXIunjxLGW"
      },
      "source": [
        "### For simplicity in the following steps, convert the dataset from a pandas DataFrame to a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "zHAfvRbkxfeH"
      },
      "outputs": [],
      "source": [
        "train_features = np.array(train_features)\n",
        "train_labels = np.array(train_labels)\n",
        "test_features = np.array(test_features)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do some sanity check on the shape of the data before building a model"
      ],
      "metadata": {
        "id": "8EbO6Usw4nNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "Jba2mTV6HXZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCfztMDkyeLX"
      },
      "source": [
        "## Normalization layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWPepaJ20buG"
      },
      "source": [
        "To ensure stable training of neural networks, we typically normalize the data. This process also enhances the convergence of the gradient descent algorithm.\n",
        "\n",
        "There is not single way to normalize the data. You can also use `scikit-learn `or `pandas` to do it. However, in this lab, we will use the normalization layer provided by tensorflow which matches the other parts of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfuJRF3syqJL"
      },
      "source": [
        "The `tf.keras.layers.Normalization` is a clean and simple way to add feature normalization into your model.\n",
        "\n",
        "The first step is to create the layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "GAOoajCuyiAa"
      },
      "outputs": [],
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsvUWg8dy8TA"
      },
      "source": [
        "Then, fit the state of the preprocessing layer to the data by calling `Normalization.adapt`.\n",
        "\n",
        "It calculates the mean and variance of each feature, and store them in the layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ozpNzkLJzHe2"
      },
      "outputs": [],
      "source": [
        "normalizer.adapt(train_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQqwlS4HzXeM"
      },
      "source": [
        "When the layer is called, it returns the input data, with each feature independently normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXHLcbqWzdmN",
        "outputId": "f0908cea-7d6f-43f8-f9bb-438fff32efc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First example: [6.00e+00 2.25e+02 1.10e+02 3.62e+03 1.87e+01 7.80e+01 0.00e+00 0.00e+00\n",
            " 1.00e+00]\n",
            "\n",
            "Normalized: [[ 0.3048616   0.2845775   0.14142872  0.7548031   1.1217592   0.4945284\n",
            "  -0.42559615 -0.50199604  0.74128604]]\n"
          ]
        }
      ],
      "source": [
        "first = train_features[0]\n",
        "print('First example:', first)\n",
        "print()\n",
        "print('Normalized:', normalizer(first).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8u33n29vmFJ"
      },
      "source": [
        "## **Approach #1:** Regression using `Linear Regression`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6anRxth1MXq"
      },
      "source": [
        "**You are welcome to use scikit-learn to perform linear regression on this dataset.**\n",
        "\n",
        "However, here we aim to implement it using TensorFlow.\n",
        "\n",
        "- As we saw in Lab Week 2, `logistic regression` is essentially a single neuron with a `sigmoid` activation function.\n",
        "\n",
        "- Similarly, `linear regression` can be viewed as a single neuron with a `linear` activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbWqUxQa2jjY"
      },
      "source": [
        "### **Step 1:** Linear regression model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "YG9lzGcf2H9o"
      },
      "outputs": [],
      "source": [
        "linear_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(9,)),\n",
        "    normalizer,\n",
        "    layers.Dense(1, activation='linear')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3pTvD0CQ5VD"
      },
      "source": [
        "**Note:** You can define your model all at once like the cell above or you can buid the model incrementaly  (suitable for your assignment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "z-Vbp7YEQ5VD"
      },
      "outputs": [],
      "source": [
        "# Defining the model incrementaly (suitable for your assignment)\n",
        "linear_model = tf.keras.Sequential()\n",
        "linear_model.add(tf.keras.layers.Input(shape=(9,)))\n",
        "linear_model.add(normalizer)\n",
        "linear_model.add(layers.Dense(1, activation='linear'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpCRMAeW2o0-"
      },
      "source": [
        "### **Step 2:** Configure the model with Keras `Model.compile()`\n",
        "\n",
        "The most important arguments to compile are the `loss` and the `optimizer`, since these define what will be optimized (`\"mean_absolute_error\"`) and how (using the `tf.keras.optimizers.Adam(learning_rate=0.1)`).\n",
        "\n",
        "**arguments:**\n",
        "- optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "- loss='mean_absolute_error'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "aun9zdxH9Mtq"
      },
      "outputs": [],
      "source": [
        "#your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAwyyRjF4cfv"
      },
      "source": [
        "### **Step 3:** Train the model using the `Model.fit()` for `100` epochs, and store the output in a variable named history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbcTeooJ4cxr"
      },
      "outputs": [],
      "source": [
        "history = linear_model.fit(train_features, train_labels, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoSWSu4peUmG"
      },
      "outputs": [],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMO4NC-05bON"
      },
      "outputs": [],
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [MPG]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiWckJwjQ5VD"
      },
      "source": [
        "### Get the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzB9rr8PQ5VD"
      },
      "outputs": [],
      "source": [
        "linear_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASE-T2jk6cAN"
      },
      "source": [
        "### **Step 4:** Evaluate the linear model on the test set using Keras `Model.evaluate()` and see the `mean_absolute_error` and save the result for future comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "FgB74EEj9GRJ"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWfd69aOXkQD"
      },
      "source": [
        "## **Approach #2:** Regression using a `Deep Neural Network (DNN)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P1NT4XmYgxv"
      },
      "source": [
        "### Solve the same problem and using deep neural network with the sample architecture;\n",
        "- 1st hidden layer no. of units =  64\n",
        "- 2nd hidden layer no. of units = 64\n",
        "- Choose appropriate `activation` functions for hidden and output layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "HDREKddrYdr5"
      },
      "outputs": [],
      "source": [
        "#your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmr97VE5Q5VD"
      },
      "source": [
        "### Print the model summary (after training). How many parameters are there in the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "piWDAAErQ5VD"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX-BabwxGI6B"
      },
      "source": [
        "## Compare the evaluation result of the two approaches, i.e., linear regression and deep neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1TA0s5PTGUd5"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq1YhvB4Q5VE"
      },
      "source": [
        "## Use the following large model and evaluate it on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "SSzitj0zQ5VE"
      },
      "outputs": [],
      "source": [
        "model_dnn_large = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='linear')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "fKbhFdPtH0v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWnubEReQ5VE"
      },
      "source": [
        "### Explain your observation. Why do you think the large model is not performing well?\n",
        "\n",
        "- hint: when the number of trainable parameters is very large (even larger than the number of data points), the model may overfit the training data. One way to solve this problem is to use more data."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}